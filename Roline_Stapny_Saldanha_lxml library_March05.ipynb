{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lxml : Python library for XML and HTML processing. \n",
    "\n",
    "The lxml XML toolkit is a Pythonic binding for the C libraries **libxml2** and **libxslt**. It is unique in that it combines the speed and XML feature completeness of these libraries with the simplicity of a native Python API, mostly compatible but superior to the well-known ElementTree API.  The latest release of lxml library works with all CPython versions from 2.7 to 3.8.\n",
    "\n",
    "lxml is a Python library which allows for easy handling of XML and HTML files, and can also be used for web scraping. There are a lot of off-the-shelf XML parsers out there, but for better results, developers sometimes prefer to write their own XML and HTML parsers. This is when the lxml library comes to play. The key benefits of this library are that it's ease of use, extremely fast when parsing large documents, very well documented, and provides easy conversion of data to Python data types, resulting in easier file manipulation.\n",
    "\n",
    "## Advantages\n",
    "\n",
    "With the continued growth of both Python and XML, there are a plethora of packages out there that help you read, generate, and modify XML files from Python scripts. Compared to most of them, the python lxml package has two big advantages:\n",
    "\n",
    "* Performance: Fast Reading and writing even fairly large XML files.\n",
    "\n",
    "* Ease of programming: python lxml library has easy syntax and more adaptive nature than other packages.\n",
    "\n",
    "## Uses\n",
    "\n",
    "* python lxml library can be used to create XML/HTML structure using elements.\n",
    "\n",
    "* python lxml library can be used to parse XML/HTML structure to retrieve information from them. \n",
    "\n",
    "This library can be used in **web scraping** i.e to get information from different web services and web resources, as these are implemented in XML/HTML format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "\n",
    "There are multiple ways to install lxml on your system.\n",
    "\n",
    "## Method 1 : Using Pip\n",
    "\n",
    "Pip is a Python package manager which is used to download and install Python libraries to your local system with ease i.e. it downloads and installs all the dependencies for the package you're installing, as well.\n",
    "\n",
    "If you have pip installed on your system, simply run the following command in terminal or command prompt:\n",
    "\n",
    "                   pip install lxml\n",
    "\n",
    "To install a specific version, specify the version name,\n",
    "                \n",
    "                pip install lxml==3.4.2\n",
    "                \n",
    "## Method 2 : Using apt-get\n",
    "\n",
    "If you're using MacOS or Linux, you can install lxml by running this command in your terminal:\n",
    "                    \n",
    "                    sudo apt-get install python-lxml\n",
    "\n",
    "for Python 2.x,\n",
    "sudo apt-get install python-lxml\n",
    "\n",
    "for Python 3.x,\n",
    "sudo apt-get install python3-lxml\n",
    "                    \n",
    "                    \n",
    "## Method 3 : Using easy_install\n",
    "\n",
    "You probably won't get to this part, but if none of the above commands works for you for some reason, try using easy_install:\n",
    "\n",
    "                    easy_install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\user\\anaconda3\\lib\\site-packages (4.3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This spotlight includes,\n",
    "\n",
    "     1. The ElementTree class of lxml.\n",
    "     2. E-factory.\n",
    "     3. ElementPath.\n",
    "     4. Basics of web scraping using lxml.\n",
    "     5. Example: Extracting the imdb rating of movies currently in theaters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The ElementTree class\n",
    "\n",
    "## 1.1. Creating HTML/XML Documents\n",
    "\n",
    "lxml has a etree class(ElementTree class), using which we can create XML/HTML elements and their subelements, which is a very useful thing if we're trying to write or manipulate an HTML or XML file. \n",
    "\n",
    "Let's try to create the basic structure of an HTML file using etree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element body at 0x23553d2ff08>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the etree mmodule from lxml\n",
    "from lxml import etree\n",
    "\n",
    "#Element class of etree is used to create a html Element. Element function only 'requires' the name of the element to be created \n",
    "root = etree.Element('html', version=\"5.0\")\n",
    "\n",
    "\n",
    "#Add subelements to the element using etree.SubElement\n",
    "#SubElement function requires the name of both the root node and the child node to be created.\n",
    "# Pass the parent node, name of the child node, and any number of optional attributes.\n",
    "\n",
    "etree.SubElement(root, 'head')\n",
    "etree.SubElement(root, 'title', bgcolor=\"red\", fontsize='22')\n",
    "etree.SubElement(root, 'body', fontsize=\"15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html version=\"5.0\">\n",
      "  <head/>\n",
      "  <title bgcolor=\"red\" fontsize=\"22\"/>\n",
      "  <body fontsize=\"15\"/>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use pretty_print=True to indent the HTML output\n",
    "print (etree.tostring(root, pretty_print=True).decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Manipulating the HTML/XML Documents\n",
    "\n",
    "Lets use the above created HTML Element as an example for manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html\n",
      "head\n",
      "title\n",
      "body\n"
     ]
    }
   ],
   "source": [
    "#ACCESSING THE TAGS\n",
    "\n",
    "#getting te tag name of a specific element, eg:root\n",
    "print(root.tag)\n",
    "\n",
    "\n",
    "#iterate over the child elements and print their tag\n",
    "for e in root:\n",
    "    print(e.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html version=\"5.0\">\n",
      "  <head/>\n",
      "  <title bgcolor=\"red\" fontsize=\"22\"/>\n",
      "  <body fontsize=\"15\"/>\n",
      "</html>\n",
      "\n",
      "<html version=\"5.0\" newAttribute=\"attributeValue\">\n",
      "  <head/>\n",
      "  <title bgcolor=\"red\" fontsize=\"22\"/>\n",
      "  <body fontsize=\"15\"/>\n",
      "</html>\n",
      "\n",
      "red\n"
     ]
    }
   ],
   "source": [
    "#ADDING ATTRIBUTES TO ELEMENTS\n",
    "\n",
    "print(etree.tostring(root, pretty_print=True).decode(\"utf-8\"))\n",
    "\n",
    "#add attribute to the element, eg: add attribute named 'newAttribute' valued 'attributeValue' to root element\n",
    "root.set('newAttribute', 'attributeValue')\n",
    "\n",
    "print(etree.tostring(root, pretty_print=True).decode(\"utf-8\"))\n",
    "\n",
    "\n",
    "# ACESSING THE ATTRIBUTES\n",
    "\n",
    "#get the attribute of the element\n",
    "print(root[1].get('bgcolor'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html version=\"5.0\" newAttribute=\"attributeValue\">\n",
      "  <head>This is the head of that file</head>\n",
      "  <title bgcolor=\"red\" fontsize=\"22\">This is the title of that file</title>\n",
      "  <body fontsize=\"15\">This is the body of that file and would contain paragraphs etc</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ADDING TEST TO ELEMENTS AND SUBELEMENTS\n",
    "\n",
    "root[0].text = \"This is the head of that file\"\n",
    "root[1].text = \"This is the title of that file\"\n",
    "root[2].text = \"This is the body of that file and would contain paragraphs etc\"\n",
    "print(etree.tostring(root, pretty_print=True).decode(\"utf-8\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "  <head>Head of HTML</head>\n",
      "  <title>I am the title!</title>\n",
      "  <body>Howdy</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#FEEDING RAW XML FOR SERIALISATION\n",
    "\n",
    "html = etree.XML('<html><head>Head of HTML</head><title>I am the title!</title><body>Howdy</body></html>')\n",
    "print(etree.tostring(html, pretty_print=True).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "  <head/>\n",
      "  <body>Howdy from File</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PARSING FROM FILES OR FILE LIKE OBJECTS - parse() function\n",
    "\n",
    "\n",
    "from io import BytesIO\n",
    "some_file_or_file_like_object = BytesIO(b\"<html><head></head><body>Howdy from File</body></html>\")\n",
    "tree = etree.parse(some_file_or_file_like_object)\n",
    "print(etree.tostring(tree, pretty_print=True).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The E-factory\n",
    "The E-factory provides a simple and compact syntax for generating XML and HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "  <head>\n",
      "    <title>This is a sample document</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <h1 class=\"title\">Hello!</h1>\n",
      "    <p>This is a paragraph with <b>bold</b> text in it!</p>\n",
      "    <p>This is another paragraph, with a\n",
      "      <a href=\"http://www.python.org\">link</a>.</p>\n",
      "    <p>Here are some reserved characters: &lt;spam&amp;egg&gt;.</p>\n",
      "    <p>And finally an embedded XHTML fragment.</p>\n",
      "  </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lxml.builder import E\n",
    "\n",
    "def CLASS(*args): # class is a reserved word in Python\n",
    "    return {\"class\":' '.join(args)}\n",
    "\n",
    "html = page = (\n",
    "    E.html(       # create an Element called \"html\"\n",
    "     E.head(\n",
    "       E.title(\"This is a sample document\")\n",
    "     ),\n",
    "     E.body(\n",
    "       E.h1(\"Hello!\", CLASS(\"title\")),\n",
    "       E.p(\"This is a paragraph with \", E.b(\"bold\"), \" text in it!\"),\n",
    "       E.p(\"This is another paragraph, with a\", \"\\n      \",\n",
    "         E.a(\"link\", href=\"http://www.python.org\"), \".\"),\n",
    "       E.p(\"Here are some reserved characters: <spam&egg>.\"),\n",
    "       etree.XML(\"<p>And finally an embedded XHTML fragment.</p>\"),\n",
    "     )\n",
    "   )\n",
    ")\n",
    "  \n",
    "\n",
    "\n",
    "print(etree.tostring(page, pretty_print=True).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ElementPath\n",
    "The ElementTree library comes with a simple XPath-like path language called ElementPath. It helps us to find Elements and Element trees.\n",
    "\n",
    "* iterfind() iterates over all Elements that match the path expression\n",
    "* findall() returns a list of matching Elements\n",
    "* find() efficiently returns only the first match\n",
    "* findtext() returns the .text content of the first match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "a\n",
      "b\n",
      "a\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "root = etree.XML(\"<root><a x='123'>aText<b/><c/><b/></a></root>\")\n",
    "\n",
    "#Find a child of an Element:\n",
    "print(root.find(\"b\"))\n",
    "print(root.find(\"a\").tag)\n",
    "\n",
    "#Find an Element anywhere in the tree:\n",
    "print(root.find(\".//b\").tag)\n",
    "\n",
    "#Find Elements with a certain attribute:\n",
    "print(root.findall(\".//a[@x]\")[0].tag)  #finds all anchor tags in the XML Tree which have an attribute x, and returns the tag of the first match.\n",
    "print(root.findall(\".//a[@y]\"))  #finds all anchor tags in the XML Tree which have an attribute x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Basics of web scraping using lxml\n",
    "\n",
    "Steps to perform webscraping :\n",
    "\n",
    "1. Send a link and get the response from the sent link\n",
    "2. Then convert response object to a byte string.\n",
    "3. Pass the byte string to ‘fromstring’ method in html class in lxml module.\n",
    "4. Get to a particular element by xpath.\n",
    "5. Use the content according to your need.\n",
    "\n",
    "I will use the **requests** python module, which is used to send HTTP requests to web URLs.  It can download a web page’s HTML given its URL.\n",
    "\n",
    "If you don't have requests installed, you can easily install it by running this command in the terminal:\n",
    "\n",
    "            pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html\n",
    "\n",
    "page = requests.get('https://store.steampowered.com/explore/new/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to use response.content rather than response.text because lxml.html.fromstring implicitly expects bytes as input.\n",
    "\n",
    "doc = lxml.html.fromstring(page.content) #Returns an object of type HTMLElement. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XPath\n",
    "\n",
    "**XPath** is a way of locating information in structured documents such as HTML or XML documents. XPath uses path expressions to select nodes or node-sets in an XML document. The node is selected by following a path or steps.\n",
    "\n",
    "The most useful path expressions are,\n",
    "\n",
    "*  /   Selects from the root node\n",
    "* //    Selects nodes in the document from the current node that match the selection no matter where they are \n",
    "* .    Selects the current node \n",
    "* ..   Selects the parent of the current node \n",
    "*  @   Selects attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This statement will return a list of all the divs in the HTML page which have an id of tab_newreleases_content\n",
    "\n",
    "new_releases = doc.xpath('//div[@id=\"tab_newreleases_content\"]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_releases = doc.xpath('//div[@id=\"tab_newreleases_content\"]')\n",
    "\n",
    "* // these double forward slashes tell lxml that we want to search for all tags in the HTML document which match our requirements\n",
    "* div tells lxml that we are searching for divs in the HTML page\n",
    "* [@id=\"tab_newreleases_content\"] tells lxml that we are only interested in those divs which have an id of tab_newreleases_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Indie, Adventure, RPG, Puzzle', 'Action, Masterpiece, Great Soundtrack, Classic', 'Management, Simulation, Strategy, Building', 'Action, Strategy, RPG, Hack and Slash', 'Adventure, Casual, Visual Novel, Simulation', 'Adventure, Sexual Content, Visual Novel, Female Protagonist', 'Indie, Simulation, Sports, Difficult', 'Simulation, Indie, Sexual Content, Nudity', 'Strategy, Tactical, World War II, Turn-Based', 'Indie, Strategy, Simulation', 'Simulation, Strategy, Indie, Casual', 'Simulation, Adventure, Casual, Indie', 'Action, Strategy, Indie, Tower Defense', 'Action, FPS, Multiplayer', 'Building, Sandbox, Physics, Destruction', 'Strategy, Free to Play, RTS, Real Time Tactics', 'Post-apocalyptic, Action, Atmospheric, FPS', 'Action, Mechs, Anime, Character Customization', 'RPG, Hack and Slash, Action RPG, Action', 'Free to Play, Casual, Indie, Visual Novel', 'Free to Play, Visual Novel, Sexual Content, Indie', 'Free to Play, Casual, Simulation, Social Deduction', 'Action, Adventure, RPG, Indie', 'Action, RPG, Anime, Open World', 'Action, RPG, Anime, Open World', 'Action, RPG, Anime, Open World', 'Battle Royale, Multiplayer, Survival, Action', 'Free to Play, Casual, Indie, Pixel Graphics', 'Action, Multiplayer, Co-op, Hunting', 'Animation & Modeling, Design & Illustration, Game Development, Pixel Graphics', 'Free to Play, Casual, Strategy, Indie', 'Simulation, Strategy, Management, Trains', 'Free to Play, Simulation, Casual, Indie', 'VR, Physics, Masterpiece, Action', 'VR, Physics, Masterpiece, Action', 'Adventure, Visual Novel, Funny, Singleplayer']\n"
     ]
    }
   ],
   "source": [
    "#EXTRACTING TAGS\n",
    "tags = new_releases[0].xpath('.//div[@class=\"tab_item_top_tags\"]')\n",
    "total_tags = []\n",
    "for tag in tags:\n",
    "    total_tags.append(tag.text_content())\n",
    "print(total_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we are doing above is that we are extracting the divs containing the tags for the games. Then we loop over the list of extracted tags and then extract the text from those tags using the text_content() method. text_content() returns the text contained within an HTML tag without the HTML markup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Example: Extracting the imdb rating of movies currently in theaters\n",
    "\n",
    "In this example, Lets extract the movies that are currently in theaters and their imdb ratings. The imdb ratings of the movies can be found at the imdb website (https://www.imdb.com/?ref_=nv_home)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1 : Exploring the webpage.\n",
    "\n",
    "* First of all, find the section where movies in theaters are displayed on the imdb website.\n",
    "* Open up Chrome developer tools and see which HTML tags contain the required data.\n",
    "* In our case, if we take a look, we can see that every seperate element in encapsulated in div tag.\n",
    "* The div tags themselves are encapsulated in the another div whose class is \"in-theaters\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](inspect_website.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step2 : import the libraries and create a HTMLElement from the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html  # the html modolue of lxml\n",
    "\n",
    "#get the webpage\n",
    "page = requests.get('https://www.imdb.com/?ref_=nv_home')\n",
    "\n",
    "#create an object of HTMLElement type from the web page contents\n",
    "html_tree = lxml.html.fromstring(page.content) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This statement below will return a list of all the divs in the HTML page which have a class of \"in-theaters\". Only one div on the page has this class name and we can take out the first element from the list ([0]) and that would be our required div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element div at 0x235553e0ef8>\n"
     ]
    }
   ],
   "source": [
    "new_releases = html_tree.xpath('//div[@class=\"in-theaters\"]')[0]\n",
    "print(new_releases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step3: Extract the movie names and the imdb ratings\n",
    "\n",
    "* The movie titles are written inside the anchor tag whose class is \"ipc-poster-card__title-href\"\n",
    "* The imdb ratings are written inside span tag whose class is \"ipc-rating-star ipc-rating-star--baseAlt ipc-rating-star--imdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "titles = new_releases.xpath('.//a[@class=\"ipc-poster-card__title-href\"]/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sonic the Hedgehog', 'The Call of the Wild', 'The Invisible Man', 'Onward', 'Birds of Prey: And the Fantabulous Emancipation of One Harley Quinn', 'Dolittle', 'Bad Boys For Life', 'Fantasy Island', '1917', 'Brahms: The Boy II', 'Impractical Jokers: The Movie', 'Jumanji: The Next Level', 'Emma.', 'My Hero Academia: Heroes Rising', 'The Photograph', 'Parasite', 'Downhill', 'Las Pildoras De Mi Novio', 'Gretel & Hansel', 'Seberg']\n"
     ]
    }
   ],
   "source": [
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = new_releases.xpath('.//span[@class=\"ipc-rating-star ipc-rating-star--baseAlt ipc-rating-star--imdb\"]/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6.8', '6.9', '7.6', '7.4', '6.6', '5.5', '7.2', '4.6', '8.4', '4.3', '7.0', '6.8', '6.9', '8.0', '6.1', '8.6', '4.9', '3.8', '5.4', '5.1']\n"
     ]
    }
   ],
   "source": [
    "print(imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step4: Store the scrapped data into csv file using pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Movie_Title' : titles, 'IMDB Ratings' : imdb}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('IMDB Ratings',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv (r'Movies_in_Theater-Rated.csv', index = False, header=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources \n",
    "\n",
    "1. https://lxml.de/\n",
    "2. https://kite.com/python/docs/lxml\n",
    "\n",
    "\n",
    "# References\n",
    "\n",
    "1. https://timber.io/blog/an-intro-to-web-scraping-with-lxml-and-python/#step-4-extract-the-titles-prices\n",
    "2. https://stackabuse.com/introduction-to-the-python-lxml-library/\n",
    "3. https://www.journaldev.com/18043/python-lxml\n",
    "\n",
    "(To view the images) GitHub link:\n",
    "https://github.com/Roline-Stapny/Splotlight/blob/master/Roline_Stapny_Saldanha_lxml%20library_March05.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
